{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7VBkjcqNNxEd"
   },
   "source": [
    "# Google Spanner\n",
    "\n",
    "> [Spanner](https://cloud.google.com/spanner) is a highly scalable database that combines unlimited scalability with relational semantics, such as secondary indexes, strong consistency, schemas, and SQL providing 99.999% availability in one easy solution.\n",
    "\n",
    "This notebook goes over how to use `Spanner` for GraphRAG with `SpannerPropertyGraphStore` class.\n",
    "\n",
    "Learn more about the package on [GitHub](https://github.com/googleapis/llama-index-spanner-python/).\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/googleapis/llama-index-spanner-python/blob/main/docs/property_graph_store.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEAGYTPgNydh"
   },
   "source": [
    "## Before You Begin\n",
    "\n",
    "To run this notebook, you will need to do the following:\n",
    "\n",
    " * [Create a Google Cloud Project](https://developers.google.com/workspace/guides/create-project)\n",
    " * [Enable the Cloud Spanner API](https://console.cloud.google.com/flows/enableapi?apiid=spanner.googleapis.com)\n",
    " * [Create a Spanner instance](https://cloud.google.com/spanner/docs/create-manage-instances)\n",
    " * [Create a Spanner database](https://cloud.google.com/spanner/docs/create-manage-databases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cboPIg-yOcxS"
   },
   "source": [
    "### ü¶úüîó Library Installation\n",
    "The integration lives in its own `llama-index-spanner` package, so we need to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AOWh6QKYVdDp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet llama-index-spanner llama-index-llms-google-genai llama-index-readers-wikipedia wikipedia pyvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7MqpDhkOiP-"
   },
   "source": [
    "**Colab only:** Run the following cell to restart the kernel or use the button to restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzgVZv0POj17",
    "outputId": "066ba1ae-c89e-427e-8a98-7f76f90155d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfIhwIryOls1"
   },
   "source": [
    "### üîê Authentication\n",
    "Authenticate to Google Cloud as the IAM user logged into this notebook in order to access your Google Cloud Project.\n",
    "\n",
    "* If you are using Colab to run this notebook, use the cell below and continue.\n",
    "* If you are using Vertex AI Workbench, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWOkHI7XOna2"
   },
   "outputs": [],
   "source": [
    "from google.colab import auth\n",
    "\n",
    "auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6xHXneICOpsB"
   },
   "source": [
    "### ‚òÅ Set Your Google Cloud Project\n",
    "Set your Google Cloud project so that you can leverage Google Cloud resources within this notebook.\n",
    "\n",
    "If you don't know your project ID, try the following:\n",
    "\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hF0481BGOsS8"
   },
   "outputs": [],
   "source": [
    "# @markdown Please fill in the value below with your Google Cloud project ID and then run the cell.\n",
    "\n",
    "PROJECT_ID = \"\"  # @param {type:\"string\"}\n",
    "\n",
    "# Set the project id\n",
    "!gcloud config set project {PROJECT_ID}\n",
    "%env GOOGLE_CLOUD_PROJECT={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4TiC0RbhOwUu"
   },
   "source": [
    "### üí° API Enablement\n",
    "The `llama-index-spanner` package requires that you [enable the Spanner API](https://console.cloud.google.com/flows/enableapi?apiid=spanner.googleapis.com) in your Google Cloud Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9f3fJd5eOyRr"
   },
   "outputs": [],
   "source": [
    "# enable Spanner API\n",
    "!gcloud services enable spanner.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5pxMMiMOzt7"
   },
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7-Pe2ADQlNJ"
   },
   "source": [
    "### Prepare documents, llm and embed_model\n",
    "\n",
    "Prepare documents from wikipedia to be added to Spanner Graph, llm and embed_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0rdoT01aRiNI",
    "outputId": "c63f6325-3e64-481e-e3d8-a3cb73be2d95"
   },
   "outputs": [],
   "source": [
    "# Get graph documents from Wikipedia\n",
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "from llama_index.embeddings.google_genai import GoogleGenAIEmbedding\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "loader = WikipediaReader()\n",
    "documents = loader.load_data(pages=[\"Google\"], auto_suggest=False)\n",
    "\n",
    "llm = GoogleGenAI(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    ")\n",
    "embed_model = GoogleGenAIEmbedding(\n",
    "    model_name=\"text-embedding-004\", embed_batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtDbLU5sO2iA"
   },
   "source": [
    "### Set Spanner database values\n",
    "Find your database values, in the [Spanner Instances page](https://console.cloud.google.com/spanner?_ga=2.223735448.2062268965.1707700487-2088871159.1707257687).\n",
    "\n",
    "NOTE:\n",
    "- The database identified by INSTANCE and DATABASE must be created beforehand.\n",
    "- The graph does NOT need to be created beforehand.\n",
    "  \n",
    "  Note: If a graph with the specified name already exists, this library will build upon it. However, for seamless operation and to avoid unexpected errors, ensure the existing graph was also created using this library. If not, please create a new graph with a different name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-I8VTIcO442"
   },
   "outputs": [],
   "source": [
    "# @title Set Your Values Here { display-mode: \"form\" }\n",
    "INSTANCE = \"\"  # @param {type: \"string\"}\n",
    "DATABASE = \"\"  # @param {type: \"string\"}\n",
    "GRAPH_NAME = \"\"  # @param {type: \"string\"}\n",
    "USE_FLEXIBLE_SCHEMA = False  # @param {type: \"boolean\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpAv-tpcO_iL"
   },
   "source": [
    "### SpannerPropertyGraphStore\n",
    "\n",
    "To initialize the `SpannerPropertyGraphStore` class you need to provide 3 required arguments and other arguments are optional and only need to pass if it's different from default ones\n",
    "\n",
    "1.   a Spanner instance id;\n",
    "2.   a Spanner database id belongs to the above instance id;\n",
    "3.   a Spanner graph name used to create a graph in the above database.\n",
    "\n",
    "#### SpannerPropertyGraphStore with flexible schema\n",
    "\n",
    "By default, SpannerPropertyGraphStore creates an underlying table for each type of nodes and edges.\n",
    "This will create many underlying tables when your graph consists of many different types of nodes and edges.\n",
    "\n",
    "SpannerPropertyGraphStore provides a flexible schema mode that stores all your nodes in a single node table and edges in a single edge table.\n",
    "\n",
    "To use it, set USE_FLEXIBLE_SCHEMA to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u589YapWQFb8"
   },
   "outputs": [],
   "source": [
    "from llama_index_spanner import SpannerPropertyGraphStore\n",
    "\n",
    "graph_store = SpannerPropertyGraphStore(\n",
    "    instance_id=INSTANCE,\n",
    "    database_id=DATABASE,\n",
    "    graph_name=GRAPH_NAME,\n",
    "    use_flexible_schema=USE_FLEXIBLE_SCHEMA,\n",
    ")\n",
    "\n",
    "print(\"Clean up existing data...\")\n",
    "graph_store.clean_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert documents into SpannerPropertyGraphStore using PropertyGraphIndex\n",
    "\n",
    "`PropertyGraphIndex` along with `kg_extractors` converts the documents into knowledge graph and then inserts it into the `PropertyGraphStore` (In our case it will be `SpannerPropertyGraphStore`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This allows running nested event loop\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMXvOpRbZdau",
    "outputId": "3c6ca58c-0e6a-4b7f-a204-eab08adb2761"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing nodes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 45.72it/s]\n",
      "Extracting paths from text with schema: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [01:58<00:00,  6.56s/it]\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:01<00:00, 11.72it/s]\n",
      "Generating embeddings: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 840/840 [00:13<00:00, 62.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for DDL operations to complete...\n",
      "Insert nodes of type `text_chunk`...\n",
      "Waiting for DDL operations to complete...\n",
      "Insert nodes of type `COMPANY`...\n",
      "Insert nodes of type `PERSON`...\n",
      "Insert nodes of type `PRODUCT`...\n",
      "Waiting for DDL operations to complete...\n",
      "Insert edges of type `COMPANY_PART_OF_COMPANY`...\n",
      "Insert edges of type `PERSON_WORKED_ON_COMPANY`...\n",
      "Insert edges of type `COMPANY_HAS_PRODUCT`...\n",
      "Insert edges of type `COMPANY_HAS_COMPANY`...\n",
      "Insert edges of type `COMPANY_HAS_ALIAS_COMPANY`...\n",
      "Insert edges of type `PERSON_LOCATED_IN_COMPANY`...\n",
      "Insert edges of type `PERSON_WORKED_ON_PRODUCT`...\n",
      "Insert edges of type `COMPANY_HAS_ALIAS_PRODUCT`...\n",
      "Insert edges of type `PERSON_HAS_COMPANY`...\n",
      "Insert edges of type `COMPANY_USED_BY_COMPANY`...\n",
      "Insert edges of type `PERSON_PART_OF_COMPANY`...\n",
      "Insert edges of type `COMPANY_WORKED_ON_COMPANY`...\n",
      "Insert edges of type `PRODUCT_PART_OF_COMPANY`...\n",
      "Insert edges of type `COMPANY_WORKED_ON_PERSON`...\n",
      "Insert edges of type `COMPANY_HAS_PERSON`...\n",
      "Insert edges of type `COMPANY_WORKED_ON_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_HAS_ALIAS_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_USED_BY_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_HAS_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_IS_A_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_USED_FOR_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_PART_OF_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_HAS_ALIAS_COMPANY`...\n",
      "Insert edges of type `COMPANY_USED_FOR_PRODUCT`...\n",
      "Insert edges of type `PRODUCT_USED_BY_COMPANY`...\n",
      "Insert edges of type `COMPANY_PART_OF_PRODUCT`...\n",
      "Insert edges of type `COMPANY_USED_FOR_COMPANY`...\n",
      "Insert edges of type `PRODUCT_USED_BY_PERSON`...\n",
      "Insert edges of type `PERSON_USED_BY_COMPANY`...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.property_graph.base.PropertyGraphIndex at 0x7f7eb15ea1e0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[\n",
    "        SchemaLLMPathExtractor(\n",
    "            possible_entities=Literal[\"PERSON\", \"COMPANY\", \"PRODUCT\"],\n",
    "            strict=False,\n",
    "            llm=llm,\n",
    "            max_triplets_per_chunk=1000,\n",
    "            num_workers=4,\n",
    "        )\n",
    "    ],\n",
    "    property_graph_store=graph_store,\n",
    "    use_async=False,\n",
    "    llm=llm,\n",
    "    embed_kg_nodes=True,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v5b572QbSi4t"
   },
   "source": [
    "#### Query the graph\n",
    "To traverse the graph in the graph store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9YpR4cauSsfG",
    "outputId": "387bb32b-c28b-4be7-efe8-7797c5914d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'google_related_nodes': ['Maps', 'Granite Systems', 'Google Search engine', 'AdSense for Mobile', 'email service', 'Google Docs', 'women', 'Marissa Mayer', 'Google Cloud Platform', 'Sun Microsystems', 'Matt Brittin', 'UniSuper', 'Unit 8200', 'BackRub', 'DoubleClick', 'Google Nest', 'suggestion feature', 'search engine', 'Google Ads', 'Andy Rubin', 'Google Home Mini', 'Larry Page', 'Israeli Defense Forces', 'YouTube', 'Gemini', 'navigation service', 'AdWords', 'Assaf Rappaport', 'Imagen', 'Yahoo!', 'Drive', 'electricity', 'operating system', 'Ubisoft', 'rooftop photovoltaic power station', 'Meet', 'Competitive Enterprise Institute', 'Craig Silverstein', 'Incognito browsing mode', 'Mathematical Sciences Research Institute', 'Google search', 'Ron Conway', 'Translate', 'National Labor Relations Board', 'Sequoia Capital', 'Google Sheets', 'Google Drive', 'NotebookLM', 'mapping service', 'Israel', '114 megawatts of power', 'SynthID Detector', 'Take-Two', 'AdSense', 'David Cheriton', 'Junglee', 'Glass', 'BigQuery', 'OSV-Scanner', 'Social Finance', 'Adobe', 'Rajeev Motwani', 'CNIL', 'Google Maps', 'mobile virtual network operator', 'Bard', 'Gmail', 'Morgan Stanley', '1.6 gigawatt of clean energy', 'Wi-Fi router', 'Google Analytics 360 Suite', 'mobile operating system', 'The Wall Street Journal', 'smart speaker', 'language translation', 'Orkut', 'Amazon', 'Google Doodle', 'Bill Ready', 'Nest', 'packaging', 'Google for Jobs', 'Chromebook', 'Incognito', 'Google Workspace', 'Google Chrome', 'Firefox', 'Google Bard', 'Chrome', 'Iowa wind farm', 'IBM', 'Google Fiber', 'Project Maven', 'language model', 'Jeff Bezos', 'Google', 'United States Department of Justice', 'Facebook', 'Google Stadia', 'Google for Entrepreneurs', 'Waze', 'Google Home', 'Google Calendar', 'AI tutoring service', 'Google Wifi', 'Sycamore', 'Credit Suisse', 'Photos', 'DeepMind Technologies', 'Earth', 'global tax structure', 'Terry Winograd', 'productivity suite', 'Google search engine', 'climate disinformation sites', 'Veo', 'Ascension', 'Australian Government', 'Kleiner Perkins', 'Nest Wifi', 'Microsoft', 'Google Translate', 'Nest Hub Max', 'Google DeepMind', 'Andy Bechtolsheim', 'Nest Audio', 'YouTube Music', 'Google Earth', 'Google Flights', '1.6 Megawatt of electricity', 'Ariel Koren', 'Stadia', 'Google+', 'smart home control', 'California Grazing', 'ChromeOS', 'Duo', 'data centers', 'solar panels', 'GOOGL', '2.6 gigawatts of wind and solar energy', 'Motorola Mobility', 'Google Home Max', 'Google Slides', 'Daydream View', 'female employees', 'James Damore', 'Inbox by Gmail', 'Google Assistant', 'Google My Business', 'offices', 'iPhones', 'satellite imagery service', 'wind and solar investment', 'GOOG', 'web browser', 'Fitbit', 'Calico', 'Stanford University', 'Reader', 'Oracle', 'web browser apps', 'Google Search', 'Google Webmaster Tools', 'Google Classroom', 'DoubleClick AdExchange', '536 megawatts of wind power', 'cloud computing', 'G Suite', 'State Policy Network', 'Google.org', 'Audio Overview', 'Chromecast', 'Sundar Pichai', 'Linwei Ding', 'H√©ctor Garc√≠a-Molina', 'note-taking', 'Google Doodles', 'Google Search Console', 'Ubisoft ports', 'scheduling service', 'Inktomi', 'GGQ1', 'Nest Mini', 'Russian government', 'PayPal', 'Google Finance', 'Year Up', 'wind farms', 'Alphabet Workers Union', 'photo sharing', 'Project Fi', 'Public Investment Fund', 'LearnLM', 'Google News', 'Sergey Brin', 'Apple', 'Pixel', 'Google logo', 'hardware products', 'Dragonfly', 'Ram Shriram', 'photo storage', 'Wiz', 'Internet business', 'online courses', 'voice query answering', 'video viewing', '240-megawatt', 'Project Vivian', 'video sharing', 'Nest Hub', 'Sidewalk Labs', 'Alphabet', 'Megan Smith', 'Google employees', 'Raxium', 'content streaming', 'renewable fuels', 'drone software', 'YouTube TV', 'Amazon.com', 'VR media viewing', 'TensorFlow', 'Project Nimbus', 'Merit America', '100% renewable energy', 'TPU', 'Novell', 'Cisco', 'Google Cloud', 'listing aggregation', 'Google applications', 'manufacturing sites', 'Nexus One', 'communication in education', 'managing assignments', '24 TWh of electricity', 'Dennis Hwang', 'Cloud', 'AdMob', 'advertising programs', 'Google Analytics', 'Android', 'Michael Moritz', 'TiSP', 'cloud storage', 'Pixel Watch', 'renewable energy', 'Hangouts', 'FBI', 'Salesforce', 'Google Pay', '169.5 megawatts of power', 'job search product', 'John Doerr', 'Alan Steremberg', 'music playback', 'Eric Schmidt', 'Google Cardboard', 'Happy Hereford wind farm', 'Google MentalPlex', 'managing public business information', 'marketing cloud offering', 'plug-in hybrid electric vehicle', 'Jeffrey Ullman', 'PageRank', 'Alphabet Inc.', 'Richard Seeborg', 'social interaction', 'time-management service', 'Froogle', 'US Department of Justice', 'Google Photos', 'Waymo', 'Google Home Hub', 'Amit Mehta', 'Nexus', 'Play Music', 'Android phone', 'Arthur Levinson', 'Larry Brilliant', 'Google Keep', 'Safari', 'Scott Hassan', 'Workspace', 'Project Nightingale', 'OpenWallet Foundation', 'Willow Garage', 'consumers', 'carbon-free energy', 'Google Books']}]\n"
     ]
    }
   ],
   "source": [
    "sample_query = \"\"\"\n",
    "  MATCH (n WHERE REGEXP_CONTAINS(n.id, 'Google')) -[e]-{1, 2} (m)\n",
    "  RETURN ARRAY_AGG(DISTINCT m.id) AS google_related_nodes\n",
    "\"\"\"\n",
    "\n",
    "print(graph_store.structured_query(sample_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xau7BXvb_6si"
   },
   "source": [
    "#### Visualize the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "pQuQzOng_9GK",
    "outputId": "2d791b28-f51a-4c20-de3b-6293fd84070d"
   },
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "net = Network(\n",
    "    notebook=True,\n",
    "    cdn_resources=\"remote\",\n",
    "    bgcolor=\"#222222\",\n",
    "    font_color=\"white\",\n",
    "    height=\"500px\",\n",
    "    width=\"50%\",\n",
    "    directed=True,\n",
    ")\n",
    "\n",
    "node_query = \"\"\"\n",
    "  MATCH (n)\n",
    "  RETURN n.id\n",
    "\"\"\"\n",
    "\n",
    "edge_query = \"\"\"\n",
    "  MATCH -[e]->\n",
    "  RETURN e.id AS src_id, e.target_id AS dst_id, labels(e)[0] AS label\n",
    "\"\"\"\n",
    "\n",
    "nodes = graph_store.structured_query(node_query)\n",
    "edges = graph_store.structured_query(edge_query)\n",
    "\n",
    "net.add_nodes([node[\"id\"] for node in nodes])\n",
    "for edge in edges:\n",
    "    net.add_edge(edge[\"src_id\"], edge[\"dst_id\"], title=edge[\"label\"])\n",
    "\n",
    "net.toggle_physics(True)\n",
    "net.show(\"graph.html\")\n",
    "display(HTML(\"graph.html\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pM7TmfI0TEFy"
   },
   "source": [
    "#### Clean up the graph\n",
    "\n",
    "> USE IT WITH CAUTION!\n",
    "\n",
    "Clean up all the nodes/edges in your graph and remove your graph definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQWq4-sITOgl",
    "outputId": "5ed5ebf2-a34b-400e-a171-71b2e863e99c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for DDL operations to complete...\n",
      "Waiting for DDL operations to complete...\n",
      "Waiting for DDL operations to complete...\n"
     ]
    }
   ],
   "source": [
    "graph_store.clean_up()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-index-spanner-w7KXNgmj-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
